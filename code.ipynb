{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data and train labels\n",
    "X_train = pd.read_csv('data/EstrogenReceptorStatus_Train.csv',index_col=0)\n",
    "y_train = pd.read_csv('data/EstrogenReceptorStatus_Train_labels.txt',header=None)\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data and test labels\n",
    "X_test = pd.read_csv('data/EstrogenReceptorStatus_Test.csv',index_col=0)\n",
    "y_test = pd.read_csv('data/EstrogenReceptorStatus_Test_labels.txt',header=None)\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 54 55\n"
     ]
    }
   ],
   "source": [
    "# split training data and labels into training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=14)\n",
    "# check training = 60%, validation = 20% and test = 20%\n",
    "print(len(y_train), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert features (data) to tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "# convert labels to tensors\n",
    "y_train = torch.LongTensor(y_train)[:,0]\n",
    "y_val = torch.FloatTensor(y_val)[:,0]\n",
    "y_test = torch.LongTensor(y_test)[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 10\n",
    "n_features = 162\n",
    "n_examples_train = 162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(weighted_sum):\n",
    "    most_probable = weighted_sum.argmax().item()\n",
    "    output = 0 if most_probable < 0 else 1\n",
    "    output = torch.tensor(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Neural Network, it is a FeedForward\n",
    "class Network(nn.Module):\n",
    "    # create the layers of the Network: input layer, two hidden layers, output layer.\n",
    "    def __init__(self, in_features=n_features, h1=30, h2=30, out_features=2):\n",
    "        super().__init__() # instantiate the model\n",
    "        torch.manual_seed(14)\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "\n",
    "    # set the activations functions that will be used in every layer\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.out(x))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "\n",
    "# set the criterion model to measure the loss/error\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "# set the optimizer and learning rate\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # go for a prediction\n",
    "    y_pred = network.forward(X_train)\n",
    "    # measure the loss/error\n",
    "    loss = loss_criterion(y_pred, y_train)\n",
    "    print(loss.item())\n",
    "    # keep track of the losses\n",
    "    losses.append(loss.detach().numpy()) # we dont want it to save it as a tensor\n",
    "\n",
    "    # back propagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model in the test data\n",
    "with torch.no_grad():\n",
    "    y_eval = network.forward(X_test)\n",
    "    loss = loss_criterion(y_eval, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8833)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network got 12 correct predictions out of 55 possibles!\n"
     ]
    }
   ],
   "source": [
    "# test the network\n",
    "correct = 0\n",
    "# dont do the back propagation\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_eval = network.forward(data)\n",
    "        # get the number of correct predicitions\n",
    "        if y_eval.argmax().item() == y_test[i]: correct += 1\n",
    "\n",
    "print(f'The network got {correct} correct predictions out of {len(y_test)} possibles!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# weight and biases run\\nimport wandb\\n# start a new wandb run to track this script\\nwandb.init(\\n    # set the wandb project where this run will be logged\\n    project=\"EstrogenReceptor_FeedForwardNN\",\\n    \\n    # track hyperparameters and run metadata\\n    config={\\n    \"learning_rate\": 0.02,\\n    \"architecture\": \"CNN\",\\n    \"dataset\": \"CIFAR-100\",\\n    \"epochs\": 10,\\n    }\\n)\\n\\nlosses = []\\nfor epoch in range(epochs):\\n    for batch in range(0, )\\n    # go for a prediction\\n    y_pred = network.forward(X_train)\\n    # measure the loss/error\\n    loss = loss_criterion(y_pred, y_train)\\n    # back propagation\\n    loss.backward()\\n    optimizer.step()\\n    optimizer.zero_grad()    \\n# [optional] finish the wandb run, necessary in notebooks\\nwandb.finish()\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# weight and biases run\n",
    "import wandb\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"EstrogenReceptor_FeedForwardNN\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(0, )\n",
    "    # go for a prediction\n",
    "    y_pred = network.forward(X_train)\n",
    "    # measure the loss/error\n",
    "    loss = loss_criterion(y_pred, y_train)\n",
    "    # back propagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
