{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data and train labels\n",
    "X_train = pd.read_csv('data/EstrogenReceptorStatus_Train.csv',index_col=0)\n",
    "y_train = pd.read_csv('data/EstrogenReceptorStatus_Train_labels.txt',header=None)\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data and test labels\n",
    "X_test = pd.read_csv('data/EstrogenReceptorStatus_Test.csv',index_col=0)\n",
    "y_test = pd.read_csv('data/EstrogenReceptorStatus_Test_labels.txt',header=None)\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 54 55\n"
     ]
    }
   ],
   "source": [
    "# split training data and labels into training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=14)\n",
    "# check training = 60%, validation = 20% and test = 20%\n",
    "print(len(y_train), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert features (data) to tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "# convert labels to tensors\n",
    "y_train = torch.LongTensor(y_train)[:,0]\n",
    "y_val = torch.FloatTensor(y_val)[:,0]\n",
    "y_test = torch.LongTensor(y_test)[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 10\n",
    "n_features = 162\n",
    "patience = 20\n",
    "n_examples_train = len(y_train)\n",
    "n_examples_test = len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(weighted_sum):\n",
    "    most_probable = weighted_sum.argmax().item()\n",
    "    output = 0 if most_probable < 0 else 1\n",
    "    output = torch.tensor(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Neural Network, it is a FeedForward\n",
    "class Network(nn.Module):\n",
    "    # create the layers of the Network: input layer, two hidden layers, output layer.\n",
    "    def __init__(self, in_features=n_features, h1=30, h2=30, out_features=1):\n",
    "        super().__init__() # instantiate the model\n",
    "        torch.manual_seed(14)\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "\n",
    "    # set the activations functions that will be used in every layer\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "# set the criterion model to measure the loss/error\n",
    "loss_criterion = nn.BCELoss()\n",
    "# set the optimizer and learning rate\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.01)\n",
    "# define early stopping function\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "losses_train = []\n",
    "stop = (n_examples_train//batch_size)*batch_size\n",
    "\n",
    "# convert the output of the softmax to 0 or 1, taking 0.5 as the thresholds\n",
    "def toBinary(prediction):\n",
    "    output = []\n",
    "    for pred in prediction:\n",
    "        if pred < 0.5: output.append(0)\n",
    "        else: output.append(1)\n",
    "    return output\n",
    "\n",
    "def training(a, b):\n",
    "    # go for a prediction\n",
    "    y_pred_train = network.forward(X_train[a:b,:])\n",
    "    # measure the loss/error\n",
    "    loss = loss_criterion(y_pred_train, torch.unsqueeze(y_train[a:b], 1).float())\n",
    "    # keep track of the losses\n",
    "    losses_train.append(loss.detach().numpy()) # we dont want it to save it as a tensor\n",
    "\n",
    "    # back propagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "# function for the test/evaluation in which we dont want back propagation, it takes into acount mini batches\n",
    "# variable that counts how many correct predictions we've got in the evaluation\n",
    "correct = 0\n",
    "def evaluation(a,b):\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(X_test[a:b,]):\n",
    "            y_eval = network.forward(data)\n",
    "            y_eval = toBinary(y_eval)\n",
    "            # get the number of correct predicitions\n",
    "            print(y_eval,y_test[i].item())\n",
    "            '''if y_eval.argmax().item() == y_test[i].item(): \n",
    "                global correct\n",
    "                correct += 1'''\n",
    "            if y_eval[0] == y_test[i].item():\n",
    "                global correct\n",
    "                correct += 1\n",
    "\n",
    "# in this function we get the indexes for the batches                \n",
    "def get_batches(n_examples, train=1): # train is used to decide if the we are on training or in testing\n",
    "    for begin in range(0, n_examples, batch_size):\n",
    "        # indexes for all the batches but the last one\n",
    "        if begin != stop:\n",
    "            # define the index for the last example that will be taken into acount in the current batch\n",
    "            final = begin+batch_size\n",
    "            # decide if it is training or testing\n",
    "            if train: training(begin, final)\n",
    "            else: evaluation(begin, final)\n",
    "        # indexes fot the last batch\n",
    "        else: \n",
    "            # decide if it is training or testing\n",
    "            if train: training(begin, X_train.shape[0])\n",
    "            else: evaluation(begin, X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.646033).  Saving model ...\n",
      "Validation loss decreased (0.646033 --> 0.627268).  Saving model ...\n",
      "Validation loss decreased (0.627268 --> 0.613320).  Saving model ...\n",
      "Validation loss decreased (0.613320 --> 0.608634).  Saving model ...\n",
      "Validation loss decreased (0.608634 --> 0.608564).  Saving model ...\n",
      "Validation loss decreased (0.608564 --> 0.606676).  Saving model ...\n",
      "Validation loss decreased (0.606676 --> 0.604908).  Saving model ...\n",
      "Validation loss decreased (0.604908 --> 0.603716).  Saving model ...\n",
      "Validation loss decreased (0.603716 --> 0.602676).  Saving model ...\n",
      "Validation loss decreased (0.602676 --> 0.601615).  Saving model ...\n",
      "Validation loss decreased (0.601615 --> 0.600601).  Saving model ...\n",
      "Validation loss decreased (0.600601 --> 0.599660).  Saving model ...\n",
      "Validation loss decreased (0.599660 --> 0.598878).  Saving model ...\n",
      "Validation loss decreased (0.598878 --> 0.597975).  Saving model ...\n",
      "Validation loss decreased (0.597975 --> 0.597059).  Saving model ...\n",
      "Validation loss decreased (0.597059 --> 0.596312).  Saving model ...\n",
      "Validation loss decreased (0.596312 --> 0.595501).  Saving model ...\n",
      "Validation loss decreased (0.595501 --> 0.594591).  Saving model ...\n",
      "Validation loss decreased (0.594591 --> 0.593672).  Saving model ...\n",
      "Validation loss decreased (0.593672 --> 0.592824).  Saving model ...\n",
      "Validation loss decreased (0.592824 --> 0.592258).  Saving model ...\n",
      "Validation loss decreased (0.592258 --> 0.591435).  Saving model ...\n",
      "Validation loss decreased (0.591435 --> 0.590322).  Saving model ...\n",
      "Validation loss decreased (0.590322 --> 0.590077).  Saving model ...\n",
      "Validation loss decreased (0.590077 --> 0.589659).  Saving model ...\n",
      "Validation loss decreased (0.589659 --> 0.588217).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Validation loss decreased (0.588217 --> 0.587481).  Saving model ...\n",
      "Validation loss decreased (0.587481 --> 0.586425).  Saving model ...\n",
      "Validation loss decreased (0.586425 --> 0.585523).  Saving model ...\n",
      "Validation loss decreased (0.585523 --> 0.583598).  Saving model ...\n",
      "Validation loss decreased (0.583598 --> 0.581885).  Saving model ...\n",
      "Validation loss decreased (0.581885 --> 0.578666).  Saving model ...\n",
      "Validation loss decreased (0.578666 --> 0.577497).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Validation loss decreased (0.577497 --> 0.576756).  Saving model ...\n",
      "Validation loss decreased (0.576756 --> 0.576295).  Saving model ...\n",
      "Validation loss decreased (0.576295 --> 0.575328).  Saving model ...\n",
      "Validation loss decreased (0.575328 --> 0.574791).  Saving model ...\n",
      "Validation loss decreased (0.574791 --> 0.574226).  Saving model ...\n",
      "Validation loss decreased (0.574226 --> 0.572558).  Saving model ...\n",
      "Validation loss decreased (0.572558 --> 0.570921).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "EarlyStopping counter: 2 out of 20\n",
      "EarlyStopping counter: 3 out of 20\n",
      "EarlyStopping counter: 4 out of 20\n",
      "EarlyStopping counter: 5 out of 20\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Validation loss decreased (0.570921 --> 0.570531).  Saving model ...\n",
      "Validation loss decreased (0.570531 --> 0.569972).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "EarlyStopping counter: 2 out of 20\n",
      "EarlyStopping counter: 3 out of 20\n",
      "EarlyStopping counter: 4 out of 20\n",
      "EarlyStopping counter: 5 out of 20\n",
      "EarlyStopping counter: 6 out of 20\n",
      "EarlyStopping counter: 7 out of 20\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Validation loss decreased (0.569972 --> 0.568695).  Saving model ...\n",
      "Validation loss decreased (0.568695 --> 0.568555).  Saving model ...\n",
      "Validation loss decreased (0.568555 --> 0.568316).  Saving model ...\n",
      "Validation loss decreased (0.568316 --> 0.567314).  Saving model ...\n",
      "Validation loss decreased (0.567314 --> 0.565567).  Saving model ...\n",
      "Validation loss decreased (0.565567 --> 0.563800).  Saving model ...\n",
      "Validation loss decreased (0.563800 --> 0.561878).  Saving model ...\n",
      "Validation loss decreased (0.561878 --> 0.560017).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "EarlyStopping counter: 2 out of 20\n",
      "EarlyStopping counter: 3 out of 20\n",
      "EarlyStopping counter: 4 out of 20\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Validation loss decreased (0.560017 --> 0.558833).  Saving model ...\n",
      "Validation loss decreased (0.558833 --> 0.556835).  Saving model ...\n",
      "Validation loss decreased (0.556835 --> 0.556794).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Validation loss decreased (0.556794 --> 0.556740).  Saving model ...\n",
      "Validation loss decreased (0.556740 --> 0.555914).  Saving model ...\n",
      "Validation loss decreased (0.555914 --> 0.554578).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "EarlyStopping counter: 2 out of 20\n",
      "EarlyStopping counter: 3 out of 20\n",
      "EarlyStopping counter: 4 out of 20\n",
      "EarlyStopping counter: 5 out of 20\n",
      "EarlyStopping counter: 6 out of 20\n",
      "EarlyStopping counter: 7 out of 20\n",
      "EarlyStopping counter: 8 out of 20\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Validation loss decreased (0.554578 --> 0.553935).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Validation loss decreased (0.553935 --> 0.553884).  Saving model ...\n",
      "Validation loss decreased (0.553884 --> 0.553270).  Saving model ...\n",
      "Validation loss decreased (0.553270 --> 0.552002).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Validation loss decreased (0.552002 --> 0.550461).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 20\n",
      "EarlyStopping counter: 2 out of 20\n",
      "EarlyStopping counter: 3 out of 20\n",
      "EarlyStopping counter: 4 out of 20\n",
      "0.7104172110557556 0.18680301308631897\n",
      "0.6460333466529846 0.4883284270763397\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    get_batches(n_examples_train)\n",
    "    # VALIDATE THE MODEL\n",
    "    y_pred_val = network.forward(X_val)\n",
    "    # measure the loss/error\n",
    "    loss = loss_criterion(y_pred_val, torch.unsqueeze(y_val, 1).float())\n",
    "    #keep track of the losses\n",
    "    losses_val.append(loss.detach().numpy())\n",
    "    early_stopping(np.average(losses_val), network)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "print(losses_train[0].item(), losses_train[-1].item())\n",
    "print(losses_val[0].item(), losses_val[-1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 0\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[1] 1\n",
      "[0] 0\n",
      "[1] 1\n",
      "Accuracy: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# test the network\n",
    "get_batches(n_examples_test, 0)\n",
    "print(f'Accuracy: {correct/len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# weight and biases run\\nimport wandb\\n# start a new wandb run to track this script\\nwandb.init(\\n    # set the wandb project where this run will be logged\\n    project=\"EstrogenReceptor_FeedForwardNN\",\\n    \\n    # track hyperparameters and run metadata\\n    config={\\n    \"learning_rate\": 0.02,\\n    \"architecture\": \"CNN\",\\n    \"dataset\": \"CIFAR-100\",\\n    \"epochs\": 10,\\n    }\\n)\\n\\nlosses = []\\nfor epoch in range(epochs):\\n    for batch in range(0, )\\n    # go for a prediction\\n    y_pred = network.forward(X_train)\\n    # measure the loss/error\\n    loss = loss_criterion(y_pred, y_train)\\n    # back propagation\\n    loss.backward()\\n    optimizer.step()\\n    optimizer.zero_grad()    \\n# [optional] finish the wandb run, necessary in notebooks\\nwandb.finish()\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# weight and biases run\n",
    "import wandb\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"EstrogenReceptor_FeedForwardNN\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(0, )\n",
    "    # go for a prediction\n",
    "    y_pred = network.forward(X_train)\n",
    "    # measure the loss/error\n",
    "    loss = loss_criterion(y_pred, y_train)\n",
    "    # back propagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
